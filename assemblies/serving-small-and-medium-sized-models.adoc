:_module-type: ASSEMBLY

ifdef::context[:parent-context: {context}]

:context: model-serving

[id="serving-small-and-medium-sized-models_{context}"]
= Serving small and medium-sized models

[role='_abstract']
As a data scientist, you can deploy your trained machine-learning models to serve intelligent applications in production. After you have deployed your model, applications can send requests to the model using its deployed API endpoint.

When you want to deploy small or medium-sized models that can share server resources, you can use the _multi-model serving platform_. On this model-serving platform, multiple models can be deployed on the same model server. 

== Configuring model servers

include::modules/enabling-the-multi-model-serving-platform.adoc[leveloffset=+2]

include::modules/adding-a-model-server-for-the-multi-model-serving-platform.adoc[leveloffset=+2]

include::modules/adding-a-custom-model-serving-runtime.adoc[leveloffset=+2]

include::modules/updating-a-model-server.adoc[leveloffset=+2]

include::modules/duplicating-a-model-server.adoc[leveloffset=+2]

include::modules/deleting-a-model-server.adoc[leveloffset=+2]

== Working with deployed models

include::modules/deploying-a-model.adoc[leveloffset=+2]

include::modules/viewing-a-deployed-model.adoc[leveloffset=+2]

include::modules/updating-the-deployment-properties-of-a-deployed-model.adoc[leveloffset=+2]

include::modules/deleting-a-deployed-model.adoc[leveloffset=+2]
//include::modules/viewing-the-performance-metrics-of-a-deployed-model.adoc[leveloffset=+2]

// [role='_additional-resources']
// == Additional resources
// *

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
