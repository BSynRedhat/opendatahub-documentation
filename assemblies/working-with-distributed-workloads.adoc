:_module-type: ASSEMBLY

ifdef::context[:parent-context: {context}]

:context: distributed-workloads

[id="working-with-distributed-workloads_{context}"]
= Working with distributed workloads

[role='_abstract']
To train complex machine-learning models or process data more quickly, data scientists can use the distributed workloads feature to run their jobs on multiple OpenShift worker nodes in parallel.
This approach significantly reduces the task completion time, and enables the use of larger datasets and more complex models.

[IMPORTANT]
====
ifdef::self-managed[]
The distributed workloads feature is currently available in {productname-long} {vernum} as a Technology Preview feature.
endif::[]
ifndef::self-managed[]
The distributed workloads feature is currently available in {productname-long} as a Technology Preview feature.
endif::[]
Technology Preview features are not supported with Red{nbsp}Hat production service level agreements (SLAs) and might not be functionally complete.
Red{nbsp}Hat does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red{nbsp}Hat Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====



include::modules/overview-of-distributed-workloads.adoc[leveloffset=+1]

include::modules/configuring-distributed-workloads.adoc[leveloffset=+1]

include::modules/running-distributed-data-science-workloads-from-notebooks.adoc[leveloffset=+1]

include::modules/running-distributed-data-science-workloads-from-ds-pipelines.adoc[leveloffset=+1]

include::modules/running-distributed-data-science-workloads-disconnected-env.adoc[leveloffset=+1]


// [role='_additional-resources']
// == Additional resources
// *

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
