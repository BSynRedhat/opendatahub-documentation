:_module-type: PROCEDURE

[id="adding-a-custom-model-serving-runtime_{context}"]
= Adding a custom model-serving runtime

A model-serving runtime provides integration with a specified model server and the model frameworks that it supports. By default, {productname-long} includes the OpenVINO Model Server runtime. However, if this runtime doesn't meet your needs (it doesn't support a particular model framework, for example), you might want to add your own, custom runtimes.

As an administrator, you can use the {productname-short} interface to add and enable custom model-serving runtimes. You can then choose from your enabled runtimes when you create a new model server.

[role='_abstract']

.Prerequisites
* You have logged in to {productname-short} as an administrator.
ifdef::upstream[]
* You are familiar with how to link:{odhdocshome}/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[add a model server to your project]. When you have added a custom model-serving runtime, you must configure a new model server to use the runtime.
endif::[]
ifndef::upstream[]
* You are familiar with how to link:{rhoaidocshome}{default-format-url}/serving-models/serving-small-and-medium-sized-models_model-serving#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[add a model server to your project]. When you have added a custom model-serving runtime, you must configure a new model server to use the runtime.
endif::[]
* You have reviewed the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository. You can use these examples as _starting points_. However, each runtime requires some further modification before you can deploy it in {productname-short}. The required modifications are described in the following procedure.
+
NOTE: {productname-short} includes the OpenVINO Model Server model-serving runtime by default. You do not need to add this runtime to {productname-short}.

.Procedure
. From the {productname-short} dashboard, click *Settings* > *Serving runtimes*.
+
The *Serving runtimes* page opens and shows the model-serving runtimes that are already installed and enabled in your {productname-short} deployment. By default, the OpenVINO Model Server runtime is pre-installed and enabled in {productname-short}.

. To add a custom runtime, choose one of the following options:
+
--
** To start with an existing runtime, click the action menu (&#8942;) next to the existing runtime and then click *Duplicate*. Skip to Step 5. 

** To add a new custom runtime, click *Add serving runtime*.
--
+
The *Add serving runtime* page opens.

. To specify the YAML code for the runtime, perform one of the following sets of actions::
+
--
* *Upload a YAML file*
.. Click *Upload files*.
+
A file browser opens.
.. In the file browser, select a YAML file on your computer. This file might be the one of the example runtimes that you downloaded from the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository.
+
The embedded YAML editor opens and shows the contents of the file that you uploaded.

* *Enter YAML code directly in the editor*
.. Click *Start from scratch*.
+
The embedded YAML editor opens with no content.
.. Enter or paste YAML code directly in the embedded editor. The YAML that you paste might be copied from one of the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository.
--

. Optional: If you are adding one of the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository, perform the following modifications:
.. In the YAML editor, locate the `kind` field for your runtime. Update the value of this field to `ServingRuntime`.
.. In the link:https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml[kustomization.yaml^] file in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository, take note of the `newName` and `newTag` values for the runtime that you want to add. You will specify these values in a later step.
.. In the YAML editor for your custom runtime, locate the `containers.image` field. 
.. Update the value of the `containers.image` field in the format `newName:newTag`, based on the values that you previously noted in the link:https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml[kustomization.yaml^] file. Some examples are shown.
+
--
Nvidia Triton Inference Server::
+
`image: nvcr.io/nvidia/tritonserver:23.04-py3`

Seldon Python MLServer::
+
`image: seldonio/mlserver:1.3.2`

TorchServe::
+
`image: pytorch/torchserve:0.7.1-cpu`
--

. In the `metadata.name` field, ensure that the value of the runtime you are adding is unique (that is, the value doesn't match a runtime that you have already added).

. Optional: To configure a custom display name for the runtime that you are adding, add a `metadata.annotations.openshift.io/display-name` field and specify a value, as shown in the following example:
+
[source]
----
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: mlserver-0.x
  annotations:
    openshift.io/display-name: MLServer
----
+
NOTE: If you do not configure a custom display name for your runtime, {productname-short} shows the value of the `metadata.name` field.

. Click *Add*.
+
The *Serving runtimes* page opens and shows the updated list of runtimes that are installed. Observe that the runtime you added is automatically enabled.

. Optional: To edit your custom runtime, click the action menu (&#8942;) and select *Edit*.
+
NOTE: You cannot directly edit the OpenVINO Model Server runtime that is included in {productname-short} by default. However, you can _clone_ this runtime and edit the cloned version. You can then add the edited clone as a new, custom runtime. To do this, click the action menu beside the OpenVINO Model Server and select *Clone*.

.Verification
* The model-serving runtime you added is shown in an enabled state on the *Serving runtimes* page.

[role='_additional-resources']
.Additional resources
ifndef::upstream[]
* To learn how to configure a model server that uses a custom model-serving runtime that you have added, see link:{rhoaidocshome}{default-format-url}/serving-models/serving-small-and-medium-sized-models_model-serving#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[Adding a model server to your data science project].
endif::[]
ifdef::upstream[]
* To learn how to configure a model server that uses a custom model-serving runtime that you have added, see link:{odhdocshome}/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[Adding a model server to your data science project].
endif::[]
