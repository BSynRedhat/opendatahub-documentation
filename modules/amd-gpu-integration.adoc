:_module-type: CONCEPT

[id='amd-gpu-integration_{context}']
= AMD GPU Integration

You can use AMD GPUs with {productname-short} to accelerate AI and machine learning (ML) workloads. AMD GPUs provide high-performance compute capabilities, allowing users to process large data sets, train deep neural networks, and perform complex inference tasks more efficiently.

Integrating AMD GPUs with {productname-short} involves the following components and benefits:

* **ROCm workbench images**: 
  Use the ROCm workbench images to streamline AI/ML workflows on AMD GPUs. These images include libraries and frameworks optimized with the AMD ROCm platform, enabling high-performance workloads for PyTorch and TensorFlow. The pre-configured images reduce setup time and provide an optimized environment for GPU-accelerated development and experimentation.

* **AMD GPU Operator**: 
  The AMD GPU Operator simplifies GPU integration by automating driver installation, device plugin setup, and node labeling for GPU resource management. It ensures compatibility between OpenShift and AMD hardware while enabling scaling of GPU-enabled workloads.

* **Why Use AMD GPUs with {productname-short}?**
  - Accelerate compute-intensive tasks such as deep learning training, inference, and data preprocessing.
  - Use the open-source ROCm platform for flexibility and performance across various frameworks.
  - Scale workloads efficiently across on-premises or cloud deployments with AMD GPUs.

By integrating AMD GPUs with {productname-short}, you can achieve significant performance improvements, reduce latency, and simplify the deployment of GPU-accelerated workloads, enabling faster time-to-value for AI and ML projects.
