:_module-type: PROCEDURE

[id="configuring-the-training-job_{context}"]
= Configuring the training job

[role='_abstract']
Before you can use a training job to finetune a model, you must configure the training job. 
The example training job in this section is based on the IBM and Hugging Face tuning example provided in link:https://github.com/foundation-model-stack/fms-hf-tuning/tree/main/examples/prompt_tuning_twitter_complaints[GitHub]. 


.Prerequisites

ifndef::upstream[]
* You have prepared a training workbench as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/finetuning-a-model-by-using-kubeflow-training__distributed-workloads#preparing-a-training-workbench_distributed-workloads[Preparing a training workbench].
endif::[]
ifdef::upstream[]
* You have prepared a training workbench as described in link:{odhdocshome}/working-with-distributed-workloads/#preparing-a-training-workbench_distributed-workloads[Preparing a training workbench].
endif::[]


.Procedure
. Open the training notebook, as follows:
.. Log in to the {productname-long} web console.
.. Click *Data science projects* and click your project.
.. Click the *Workbenches* tab. 
If your training workbench is not already running, start the workbench.
.. Click the *Open* link to open the IDE in a new window. 
.. In the IDE, open the `my_training_notebook.ipynb` notebook.

. Create a cell with the following content to declare the training parameters:
+
[source,subs="+quotes"]
----
%%yaml parameters

# Model
model_name_or_path: Meta-Llama/Meta-Llama-3.1-8B-Instruct
model_revision: main
torch_dtype: bfloat16
attn_implementation: flash_attention_2

# PEFT / LoRA
use_peft: true
lora_r: 16
lora_alpha: 8
lora_dropout: 0.05
lora_target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
lora_modules_to_save: []
init_lora_weights: true

# Quantization / BitsAndBytes
load_in_4bit: false                       # use 4 bit precision for the base model (only with LoRA)
load_in_8bit: false                       # use 8 bit precision for the base model (only with LoRA)

# Datasets
dataset_name: gsm8k                       # id or path to the dataset
dataset_config: main                      # name of the dataset configuration
dataset_train_split: train                # dataset split to use for training
dataset_test_split: test                  # dataset split to use for evaluation
dataset_text_field: text                  # name of the text field of the dataset
dataset_kwargs:
  add_special_tokens: false               # template with special tokens
  append_concat_token: false              # add additional separator token

# SFT
max_seq_length: 1024                      # max sequence length for model and packing of the dataset
dataset_batch_size: 1000                  # samples to tokenize per batch
packing: false
use_liger: false

# Training
num_train_epochs: 10                      # number of training epochs

per_device_train_batch_size: 32           # batch size per device during training
per_device_eval_batch_size: 32            # batch size for evaluation
auto_find_batch_size: false               # find a batch size that fits into memory automatically
eval_strategy: epoch                      # evaluate every epoch

bf16: true                                # use bf16 16-bit (mixed) precision
tf32: false                               # use tf32 precision

learning_rate: 1.0e-4                     # initial learning rate
warmup_steps: 10                          # steps for a linear warmup from 0 to `learning_rate`
lr_scheduler_type: inverse_sqrt           # learning rate scheduler (see transformers.SchedulerType)

optim: adamw_torch_fused                  # optimizer (see transformers.OptimizerNames)
max_grad_norm: 1.0                        # max gradient norm
seed: 42

gradient_accumulation_steps: 1            # number of steps before performing a backward/update pass
gradient_checkpointing: false             # use gradient checkpointing to save memory
gradient_checkpointing_kwargs:
  use_reentrant: false

# FSDP
fsdp: "full_shard auto_wrap offload"      # remove offload if enough GPU memory
fsdp_config:
  activation_checkpointing: true
  cpu_ram_efficient_loading: false
  sync_module_states: true
  use_orig_params: true
  limit_all_gathers: false

# Checkpointing
save_strategy: epoch                      # save checkpoint every epoch
save_total_limit: 1                       # limit the total amount of checkpoints
resume_from_checkpoint: false             # load the last checkpoint in output_dir and resume from it

# Logging
log_level: warning                        # logging level (see transformers.logging)
logging_strategy: steps
logging_steps: 1                          # log every N steps
report_to:
- tensorboard                             # report metrics to tensorboard

output_dir: /mnt/shared/Meta-Llama-3.1-8B-Instruct
----


.. Edit the metadata of the training-job configuration as shown in the following table.
+
.Training-job configuration metadata
[cols="16,84"]
|===
|Parameter | Value

|`name`
|Name of the training-job configuration

|`namespace`
|Name of your project
|===

.. Edit the parameters of the training-job configuration as shown in the following table.
+
.Training-job configuration parameters
[cols="30,70"]
|===
|Parameter | Value

|`model_name_or_path`
|Name of the pre-trained model or the path to the model in the training-job container; in this example, the model name is taken from the Hugging Face web page

|`training_data_path`
|Path to the training data that you set in the `training_data.yaml` ConfigMap

|`output_dir`
|Output directory for the model

|`save_model_dir`
|Directory where the tuned model is saved

|`num_train_epochs`
|Number of epochs for training; in this example, the training job is set to run 10 times

|`per_device_train_batch_size`
|Batch size, the number of data set examples to process together; in this example, the training job processes 4 examples at a time

|`per_device_eval_batch_size`
|Batch size, the number of data set examples to process together per GPU or TPU core or CPU; in this example, the training job processes 4 examples at a time

|`gradient_accumulation_steps`
|Number of gradient accumulation steps

|`save_strategy`
|How often model checkpoints can be saved; the default value is `"epoch"` (save model checkpoint every epoch), other possible values are `"steps"` (save model checkpoint for every training step) and `"no"` (do not save model checkpoints)

|`save_total_limit`
|Number of model checkpoints to save; omit if `save_strategy` is set to `"no"` (no model checkpoints saved)

|`learning_rate`
|Learning rate for the training

|`weight_decay`
|Weight decay to apply

|`lr_scheduler_type`
|Optional: Scheduler type to use; the default value is `"linear"`, other possible values are `"cosine"`, `"cosine_with_restarts"`, `"polynomial"`, `"constant"`, and `"constant_with_warmup"`

|`include_tokens_per_second`
|Optional: Whether or not to compute the number of tokens per second per device for training speed metrics

|`response_template`
|Template formatting for the response

|`dataset_text_field`
|Dataset field for training output, as set in the `training_data.yaml` config map

|`padding_free`
|Whether to use a technique to process multiple examples in a single batch without adding padding tokens that waste compute resources; if used, this parameter must be set to `["huggingface"]`

|`multipack`
|Whether to use a technique for multi-GPU training to balance the number of tokens processed in each device, to minimize waiting time; you can experiment with different values to find the optimum value for your training job

|`use_flash_attn`
|Whether to use flash attention

|`peft_method`
|Tuning method: for full fine-tuning, omit this parameter; for LoRA and QLoRA, set to `"lora"`; for prompt tuning, set to `"pt"`

|`lora_r`
|LoRA: Rank of the low-rank decomposition

|`lora_alpha`
|LoRA: Scale the low-rank matrices to control their influence on the model's adaptations

|`lora_dropout`
|LoRA: Dropout rate applied to the LoRA layers, a regularization technique to prevent overfitting

|`bias`
|LoRA: Whether to adapt bias terms in the model; setting the bias to `"none"` indicates that no bias terms will be adapted

|`target_modules`
|LoRA: Names of the modules to apply LoRA to; to include all linear layers, set to "all_linear"; optional parameter for some models

|`auto_gptq`
|QLoRA: Sets 4-bit GPTQ-LoRA with AutoGPTQ; when used, this parameter must be set to `["triton_v2"]` 

|`torch_dtype`
|QLoRA: Tensor datatype; when used, this parameter must be set to `float16`

|`fp16`
|QLoRA: Whether to use half-precision floating-point format; when used, this parameter must be set to `true` 

|`fused_lora`
|QLoRA: Whether to use fused LoRA for more efficient LoRA training; if used, this parameter must be set to `["auto_gptq", true]`

|`fast_kernels`
|QLoRA: Whether to use fast cross-entropy, rope, rms loss kernels; if used, this parameter must be set to `[true, true, true]`

|===

.. Save your changes in the `config_trainingjob.yaml` file.
.. Apply the configuration to create the `training-config` object:
+
[source]
----
$ oc apply -f config_trainingjob.yaml
----

. Create the training data.
+
[NOTE]
====
The training data in this simple example is for demonstration purposes only, and is not suitable for production use.
The usual method for providing training data is to use persistent volumes. 
====
.. Create a YAML file named `training_data.yaml`.
.. Add the following `ConfigMap` object definition:
+
[source]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: twitter-complaints
  namespace: kfto
data:
  twitter_complaints.json: |
    [
        {"Tweet text":"@HMRCcustomers No this is my first job","ID":0,"Label":2,"text_label":"no complaint","output":"### Text: @HMRCcustomers No this is my first job\n\n### Label: no complaint"},
        {"Tweet text":"@KristaMariePark Thank you for your interest! If you decide to cancel, you can call Customer Care at 1-800-NYTIMES.","ID":1,"Label":2,"text_label":"no complaint","output":"### Text: @KristaMariePark Thank you for your interest! If you decide to cancel, you can call Customer Care at 1-800-NYTIMES.\n\n### Label: no complaint"},
        {"Tweet text":"@EE On Rosneath Arial having good upload and download speeds but terrible latency 200ms. Why is this.","ID":3,"Label":1,"text_label":"complaint","output":"### Text: @EE On Rosneath Arial having good upload and download speeds but terrible latency 200ms. Why is this.\n\n### Label: complaint"},
        {"Tweet text":"Couples wallpaper, so cute. :) #BrothersAtHome","ID":4,"Label":2,"text_label":"no complaint","output":"### Text: Couples wallpaper, so cute. :) #BrothersAtHome\n\n### Label: no complaint"},
        {"Tweet text":"@mckelldogs This might just be me, but-- eyedrops? Artificial tears are so useful when you're sleep-deprived and sp… https:\/\/t.co\/WRtNsokblG","ID":5,"Label":2,"text_label":"no complaint","output":"### Text: @mckelldogs This might just be me, but-- eyedrops? Artificial tears are so useful when you're sleep-deprived and sp… https:\/\/t.co\/WRtNsokblG\n\n### Label: no complaint"},
        {"Tweet text":"@Yelp can we get the exact calculations for a business rating (for example if its 4 stars but actually 4.2) or do we use a 3rd party site?","ID":6,"Label":2,"text_label":"no complaint","output":"### Text: @Yelp can we get the exact calculations for a business rating (for example if its 4 stars but actually 4.2) or do we use a 3rd party site?\n\n### Label: no complaint"},
        {"Tweet text":"@nationalgridus I have no water and the bill is current and paid. Can you do something about this?","ID":7,"Label":1,"text_label":"complaint","output":"### Text: @nationalgridus I have no water and the bill is current and paid. Can you do something about this?\n\n### Label: complaint"},
        {"Tweet text":"@JenniferTilly Merry Christmas to as well. You get more stunning every year ��","ID":9,"Label":2,"text_label":"no complaint","output":"### Text: @JenniferTilly Merry Christmas to as well. You get more stunning every year ��\n\n### Label: no complaint"}
    ]

----
.. Replace the example namespace value `kfto` with the name of your project.
.. Replace the example training data with your training data.
.. Save your changes in the `training_data.yaml` file.
.. Apply the configuration to create the training data:
+
[source]
----
$ oc apply -f training_data.yaml
----

. Create a persistent volume claim (PVC), as follows:
.. Create a YAML file named `trainedmodelpvc.yaml`.
.. Add the following `PersistentVolumeClaim` object definition:
+
[source]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: trained-model
  namespace: kfto
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi

----
.. Replace the example namespace value `kfto` with the name of your project, and update the other parameters to suit your environment.
To calculate the `storage` value, multiply the model size by the number of epochs, and add a little extra as a buffer.
.. Save your changes in the `trainedmodelpvc.yaml` file.
.. Apply the configuration to create a Persistent Volume Claim (PVC) for the training job:
+
[source]
----
$ oc apply -f trainedmodelpvc.yaml
----





.Verification
ifdef::upstream,self-managed[]
. In the {openshift-platform} console, select your project from the *Project* list. 
endif::[]
ifdef::cloud-service[]
. In the OpenShift console, select your project from the *Project* list.
endif::[]
. Click *ConfigMaps* and verify that the `training-config` and `twitter-complaints` ConfigMaps are listed. 
. Click *Search*. From the *Resources* list, select *PersistentVolumeClaim* and verify that the `trained-model` PVC is listed.


////
[role='_additional-resources']
.Additional resources
<Do we want to link to additional resources?>


* link:https://url[link text]
////
