:_module-type: PROCEDURE

ifdef::context[:parent-context: {context}]
[id="guardrails-orchestrator-demo_{context}"]
= Guardrails orchestrator demonstration

[role='_abstract']
This demo explores how to use the TrustyAI Guardrails Orchestrator service to moderate LLM output content, by guardrailing the LLM from generating any personally identifiable information (PII). Specifically, we are guardrailing against our LLM generating email addresses and social security numbers.

In this demo, first set up your namespace with the relevant deployment, service, and route objects. Then, navigate to your {productname-short} console and run the Guardrails Orchestrator service on your LLM. 

.Prerequisites
* You have enabled KServe Raw Deployment mode.
* You have set the TrustyAI component in the `DataScienceCluster` of your {productname-short} instance to "Managed".
* You have an LLM deployed in your namespace.
* You have created a detectors `configMap`.
* You have created an orchestrator `configMap`.
* (Optional) If you are using vLLm gateway, you have created a vLLM gateway image `configMap`.


.Procedure
. Create the deployment, service, and route objects in the `model-namespace` project:
.. Deploy the detectors `configmap` using the following YAML command: `oc apply -f detectors_cm.yaml`.
.. Deploy the orchestrator `configmap` using the following YAML command: `oc apply -f resources/orchestrator_cm.yaml`.
.. Deploy the Guardrails Orchestrator custom resource (CR) using the following YAML command: `oc apply -f guardrails_crd.yaml`.
.. (Optional) Deploy the vLLM gateway image `configmap` using the following YAML command: `oc apply -f resources/vllm_images_cm.yaml`.
. In your {productname-short} console, navigate to the `model-namespace` project and observe the *Workloads* -> *Pods* section. Notice that there is a `GuardrailsOrchestrator` pod, in addition to the LLM pods.
. Click the `GuardrailsOrchestrator` pod.
. Click the *Terminal* tab and select the `gorch-test-gateway` container from the dropdown menu.
. Query the `/passthrough/v1/chat/completions` from the container terminal to generate content without any guardrails, with the `model` field set to the name of the model to query, and the `messages` field containing the input prompts:
+
[source]
----
curl localhost:8090/passthrough/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "llm",
    "messages": [
        {
            "role": "user",
            "content": "say hello to me at someemail@somedomain.com"
        },
        {
            "role": "user",
            "content": "btw here is my social 123456789"
        }
    ]
}'
----
. Click the *Logs* tab and select the `gorch-test-gateway` container from the dropdown menu to view the output.
. Return to the `gorch-test-gateway` container terminal and query the `/pii/v1/chat/completions` endpoint to perform completions while guardrailing against PII:
+
[source]
----
curl localhost:8090/passthrough/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
   "model": "llm",
   "messages": [
       {
           "role": "user",
           "content": "say hello to me at someemail@somedomain.com"
       },
       {
           "role": "user",
           "content": "btw here is my social 123456789"
       }
   ]
}'
----
+
. Click on the `Logs` tab and select the `gorch-test-gateway` container to view the output, which now contains a message similar to the following: "Unsuitable input detected, Please check the detected entities on your input and try again with the unsuitable input removed".
