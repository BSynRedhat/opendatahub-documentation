:_module-type: CONCEPT

[id='overview-of-distributed-workloads_{context}']
= Overview of distributed workloads

[role='_abstract']
You can use the distributed workloads feature to scale, queue, and manage the resources required to run machine-learning and Python workloads across multiple nodes in an OpenShift cluster simultaneously.

Distributed workloads provide the following benefits:

* You can iterate faster and experiment more frequently because of the reduced processing time.
* You can use larger datasets, which can lead to more accurate models.
* You can use complex models that could not be trained on a single node.

The distributed workloads infrastructure includes the following components:

* *CodeFlare SDK:* Defines and controls the remote distributed compute jobs and infrastructure for any Python-based environment

* *KubeRay:* Manages remote Ray clusters on OpenShift for running distributed compute workloads

* *Multi-Cluster Application Dispatcher (MCAD):* Manages the queue of batch jobs






////
[role="_additional-resources"]
.Additional resources
* link:https://url/[link text]
////
