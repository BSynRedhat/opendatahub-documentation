:_module-type: CONCEPT

[id='overview-of-model-monitoring_{context}']
= Overview of model monitoring

[role='_abstract']

To ensure that machine-learning models are transparent, fair, and reliable, data scientists can use TrustyAI in {productname-short} to monitor their data science models.

Data scientists can monitor their data science models in {productname-short} for the following metrics:

Bias::
Check for unfair patterns or biases in data and model predictions to ensure your model's decisions are unbiased.

Data drift::
Detect changes in input data distributions over time by comparing the latest real-world data to the original training data. Comparing the data identifies shifts or deviations that could impact model performance, ensuring that the model remains accurate and reliable.

<<<<<<< Updated upstream
ifdef::upstream[]
Explainability::
Understand how your model makes its predictions and decisions.

LLM evaluation::
Monitor your Large Language Models (LLMs) against a range of metrics, in order to ensure the accuracy and quality of its output.
endif::[]
=======
Large language model (LLM) evaluation:: 
Monitor your LLMs against a range of metrics to ensure the quality of its output, such as  summarization,language toxicity, and question-answering accuracy.

>>>>>>> Stashed changes
