:_module-type: CONCEPT

[id="overview-of-rag_{context}"]
= Overview of RAG

Retrieval-augmented generation (RAG) in {productname-short} extends the capabilities of large language models (LLMs) by integrating domain-specific data sources directly into the modelâ€™s context. Domain-specific data sources can be structured data, such as relational database tables, or unstructured data, such as PDF documents.

RAG indexes content and builds an embedding store that data scientists and AI engineers can query. When data scientists or AI engineers pose a question to a RAG chat bot, the RAG pipeline retrieves the most relevant pieces of data, passes them to the LLM as context, and generates a response that reflects both the prompt and the retrieved content.

By implementing RAG, data scientists and AI engineers can obtain tailored, accurate, and verifiable answers to complex queries based on their own datasets within a data science project.