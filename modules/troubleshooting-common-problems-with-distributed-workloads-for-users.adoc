:_module-type: REFERENCE

[id="troubleshooting-common-problems-with-distributed-workloads_{context}"]
= Troubleshooting common problems with distributed workloads

[role='_abstract']
If you are experiencing errors in {productname-long} relating to distributed workloads, read this section to understand what could be causing the problem, and how to resolve the problem.

ifndef::upstream[]
If you cannot see the problem here or in the release notes, contact {org-name} Support.
endif::[]

== Ray cluster is in suspended state

.Problem
The resource quota specified in the cluster queue configuration is insufficient, or the resource flavor is not yet created.

.Diagnosis
Check the status of the `Workloads` resource that is created with the `RayCluster` resource.
The `status.conditions.message` field provides the reason for the suspended state, as shown in the following example:

[source,bash]
----
status:
 conditions:
   - lastTransitionTime: '2024-05-29T13:05:09Z'
     message: 'couldn''t assign flavors to pod set small-group-jobtest12: insufficient quota for nvidia.com/gpu in flavor default-flavor in ClusterQueue'

----

.Resolution
Check your cluster queue configuration to ensure that the resources that you requested are within the limits defined for the project.
Either reduce your requested resources, or contact your administrator to request more resources. 

== Ray cluster is in failed state

.Problem
The Ray cluster head pod or worker pods are not running, perhaps because the user has insufficient resources.

.Diagnosis
When a Ray cluster is created, it initially enters a `failed` state. 
This failed state usually resolves after the reconciliation process completes and the Ray cluster pods are running.

.Resolution
If the failed state persists, review the pod events to identify the cause of the problem.
If you cannot resolve the problem, contact your administrator to request assistance.

== Error Message: Failed to call CodeFlare Operator webhook

.Problem
After you run the `cluster.up()` command, the following error is shown:

[source,bash]
----
ApiException: (500)
Reason: Internal Server Error
HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Internal error occurred: failed calling webhook \"mraycluster.ray.openshift.ai\": failed to call webhook: Post \"https://codeflare-operator-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\": no endpoints available for service \"codeflare-operator-webhook-service\"","reason":"InternalError","details":{"causes":[{"message":"failed calling webhook \"mraycluster.ray.openshift.ai\": failed to call webhook: Post \"https://codeflare-operator-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\": no endpoints available for service \"codeflare-operator-webhook-service\""}]},"code":500}
----

.Diagnosis
The CodeFlare Operator pod might not be running.

.Resolution
Contact your administrator to request assistance.

== Error Message: Failed to call Kueue webhook

.Problem
After you run the `cluster.up()` command, the following error is shown:

[source,bash]
----
ApiException: (500)
Reason: Internal Server Error
HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"Internal error occurred: failed calling webhook \"mraycluster.kb.io\": failed to call webhook: Post \"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\": no endpoints available for service \"kueue-webhook-service\"","reason":"InternalError","details":{"causes":[{"message":"failed calling webhook \"mraycluster.kb.io\": failed to call webhook: Post \"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\": no endpoints available for service \"kueue-webhook-service\""}]},"code":500}

----

.Diagnosis
The Kueue pod might not be running.

.Resolution
Contact your administrator to request assistance.


== Ray Cluster remains in “Starting” status and no pods are created

.Problem
After you run the `cluster.up()` command, when you run either the `cluster.details()` command or the `cluster.status()` command, the Ray Cluster remains in the `Starting` status instead of changing to the `Ready` status.

.Diagnosis
Check the status of the `Workloads` resource that is created with the `RayCluster` resource.
The `status.conditions.message` field provides the reason for remaining in the `Starting` state.
Similarly, check the `status.conditions.message` field for the `RayCluster` resource. 

.Resolution
If you cannot resolve the problem, contact your administrator to request assistance.

== Error Message: Default local queue not found 


.Problem
After you run the `cluster.up()` command, the following error is shown:

[source,bash]
----
Default Local Queue with kueue.x-k8s.io/default-queue: true annotation not found please create a default Local Queue or provide the local_queue name in Cluster Configuration.
----

.Diagnosis
No default local queue is defined, and a local queue is not specified in the cluster configuration.

.Resolution
ifdef::upstream,self-managed[]
. In the {openshift-platform} console, select your project from the *Project* list. 
endif::[]
ifdef::cloud-service[]
. In the OpenShift console, select your project from the *Project* list.
endif::[]
. Click *Search*, and from the *Resources* list, select *LocalQueue*.
. Resolve the problem in one of the following ways:

* If a local queue exists, add it to your cluster configuration as follows:
+
[source,bash,subs="+quotes"]
----
local_queue="_<local_queue_name>_"
----

* If no local queue exists, contact your administrator to request assistance.

 
== Error Message: Local queue does not exist

.Problem
After you run the `cluster.up()` command, the following error is shown:

[source,bash]
----
local_queue provided does not exist or is not in this namespace. Please provide the correct local_queue name in Cluster Configuration.
----

.Diagnosis
An incorrect value is specified for the local queue in the cluster configuration, or an incorrect default local queue is defined.
The specified local queue either does not exist, or exists in a different namespace.

.Resolution
. In the {openshift-platform} console, select your project from the *Project* list. 
endif::[]
ifdef::cloud-service[]
. In the OpenShift console, select your project from the *Project* list.
endif::[]
. Click *Search*, and from the *Resources* list, select *LocalQueue*.
. Resolve the problem in one of the following ways:

* If a local queue exists, ensure that you spelled the local queue name correctly in your cluster configuration, and that the `namespace` value in the cluster configuration matches your project name.
If you do not specify a `namespace` value in the cluster configuration, the Ray cluster is created in the current project.

* If no local queue exists, contact your administrator to request assistance.

== Cannot create a Ray cluster or submit jobs

.Problem
After you run the `cluster.up()` command, an error similar to the following error is shown:

[source,bash]
----
RuntimeError: Failed to get RayCluster CustomResourceDefinition: (403)
Reason: Forbidden
HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"rayclusters.ray.io is forbidden: User \"system:serviceaccount:regularuser-project:regularuser-workbench\" cannot list resource \"rayclusters\" in API group \"ray.io\" in the namespace \"regularuser-project\"","reason":"Forbidden","details":{"group":"ray.io","kind":"rayclusters"},"code":403}
----

.Diagnosis
The correct OpenShift login credentials are not specified in the `TokenAuthentication` section of your notebook code.

.Resolution
. Identify the correct OpenShift login credentials as follows:

ifdef::upstream,self-managed[]
.. In the {openshift-platform} console header, click your username and click *Copy login command*.
endif::[]
ifdef::cloud-service[]
.. In the OpenShift console header, click your username and click *Copy login command*.
endif::[]

.. In the new tab that opens, log in as the user whose credentials you want to use.
.. Click *Display Token*.
.. From the *Log in with this token* section, copy the `token` and `server` values.

. In your notebook code, specify the copied `token` and `server` values as follows:
+
[source,bash,subs="+quotes"]
----
auth = TokenAuthentication(
    token = "_<token>_",
    server = "_<server>_",
    skip_tls=False
)
auth.login()
----


== Kueue does not monitor Ray cluster or PyTorch job

.Problem
Kueue does not monitor the Ray cluster, or PyTorch jobs, or other machine-learning frameworks.

.Diagnosis
The resources (for example,`RayCluster` resources and `PyTorchJob` resources) are not created.

.Resolution
Contact your administrator to request assistance.

== Pod provisioned by Kueue is terminated before image is pulled

.Problem
Kueue waits for a period of time before marking a workload as ready, to enable all of the workload pods to become provisioned and running. 
By default, Kueue waits for 5 minutes. 
If the pod image is very large and is still being pulled after the 5-minute waiting period elapses, Kueue fails the workload and terminates the related pods.

.Diagnosis
Review the Events of the Ray head pod to check whether the image pull completed successfully.

.Resolution
If the pod takes more than 5 minutes to pull the image, contact your administrator to request assistance.


// [role='_additional-resources']
// == Additional resources
// * TODO
