:_module-type: PROCEDURE

[id="using-a-distributed-workload_{context}"]
= Using distributed workloads

[role='_abstract']
To configure the distributed workloads feature for your data scientists to use in {productname-short}, you must enable several components.

.Prerequisites
* You have logged in to {openshift-platform}.
* You have the `cluster-admin` role in {openshift-platform}.
* You have access to a Ray cluster image. For information about how to create a Ray cluster, see the link:https://docs.ray.io/en/latest/index.html[Ray documentation].
* You have sufficient resources. In addition to the base {productname-short} resources, you need 1.1 vCPU and 1.6 GB memory to deploy the distributed workloads infrastructure.
* You have logged in to {productname-long}.
ifndef::upstream[]
* If you want to use graphics processing units (GPUs), you have enabled GPU support in {productname-short}. See {rhodsdocshome}{default-format-url}/managing_users_and_user_resources/enabling-gpu-support-in-data-science[Enabling GPU support in {productname-short}].
endif::[]

.Procedure
. Log in to the {openshift-platform} web console.
. Enable the required components, as follows:
.. Click *Operators* -> *Installed Operators*.
.. Search for the *Red Hat OpenShift Data Science* Operator, and click the Operator name to open the Operator details page.
.. Click the *Data Science Cluster* tab.
.. Click the *rhods* cluster.
.. Click the *YAML* tab.
.. In the `spec.components` section, ensure that the `managementState` is set correctly for the required components depending on whether the distributed workload is run from a pipeline or notebook, as shown in the following table.
+
|===
|Component | Pipelines | Notebooks

|`codeflare`
|`Managed`
|`Managed`

|`dashboard`
|`Managed`
|`Managed`

|`datasciencepipelines`
|`Managed`
|`Removed`

|`ray`
|`Managed`
|`Managed`

|`workbenches`
|`Removed`
|`Managed`
|===

.. Click *Save*.
After a short time, the components are ready.
. Check the status of the components, as follows:
.. In the {openshift-platform} web console, click *Workloads* -> *Deployments*.
.. Search for the *codeflare-operator-manager* deployment, and click the deployment name to open the deployment details page.
.. Click the *Pods* tab.
When the status of the `codeflare-operator-manager-_<pod-id>_` is `Running`, the pod is ready to use.
To see more information about the pod, click the pod name to open the pod details page, and click the *Logs* tab.
. Log in to {productname-long}: click the application launcher (image:images/osd-app-launcher.png[The application launcher]) and click *{productname-long}*.
. Start the notebook server, as follows:
.. On the *Applications > Enabled* page, in the *Jupyter* tile, click *Launch application*.
The *Start a notebook server* page opens.
.. In the *Notebook image* section, select the *Standard Data Science* image.
Expand the *Versions* section, and select the latest version.
.. Click *Start server*.
.. After a few minutes, when the server is ready, click *Open in new tab*.
.. On the Authorize Access page, click *Allow selected permissions*.
The JupyterLab interface opens in a new tab.
. Clone the `codeflare-sdk` repository as follows:
.. In the JupyterLab interface, click *Git > Clone a Repository*.
The "Clone a repo" dialog opens.
.. In the *Enter the URI of the remote Git repository* field, enter `https://github.com/project-codeflare/codeflare-sdk.git` and click *Clone*.
The `codeflare-sdk` repository is listed in the left navigation pane.
. Run a distributed workload job as follows:
.. In the JupyterLab interface, in the left navigation pane, double-click *codeflare-sdk*.
.. Double-click *demo-notebooks -> guided-demos*.
.. Update each example demo notebook to replace the links to the example community image with a link to your Ray cluster image.
.. Update each example demo notebook to set `instascale` to `False`.
Instascale is not deployed in the Technology Preview version of the distributed workloads feature.
.. Run the notebooks.


.Verification
The notebooks run to completion without errors. In the notebooks, the output from the `cluster.status()` function indicates that the Ray cluster is `Active`.

////
[role='_additional-resources']
.Additional resources
<Do we want to link to additional resources?>


* link:https://url[link text]
////
